{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7107540-90c9-4210-a071-de7f48e88631",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9e5acf7-9b34-4dfa-b22d-643f435e2c44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from LibAUC.libauc.losses import MultiLabelAUCMLoss,CrossEntropyLoss\n",
    "from LibAUC.libauc.optimizers import PESG,Adam\n",
    "from LibAUC.libauc.models import resnet34 as Resnet34\n",
    "from LibAUC.libauc.datasets import CheXpert\n",
    "from LibAUC.libauc.metrics import auc_roc_score # for multi-task\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch \n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b12045ab-e352-4ede-8138-424c44948329",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_all_seeds(SEED):\n",
    "    # REPRODUCIBILITY\n",
    "    torch.manual_seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "warnings.simplefilter(action='ignore',category=FutureWarning) # Delete Future Warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef52c2e3-2b30-4e8f-9d86-97c559a8f9c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# paramaters\n",
    "SEED = 123\n",
    "BATCH_SIZE = 32\n",
    "lr = 0.1\n",
    "epoch_decay = 2e-3\n",
    "weight_decay = 1e-5\n",
    "margin = 1.0\n",
    "total_epochs = 6\n",
    "os.makedirs(os.path.join(os.getcwd(),'pth_files'),exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d56617b-5a08-43d7-8178-d12143022156",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.1+cu118\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7399509b-305a-4ac5-ac22-7bdc3294d089",
   "metadata": {},
   "source": [
    "# Origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59b2fbcd-9b7a-4d8c-950c-32f52fe63415",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-label mode: True, Number of classes: [5]\n",
      "------------------------------\n",
      "Found 133781 images in total, 16297 positive images, 117484 negative images\n",
      "Cardiomegaly(C0): imbalance ratio is 0.1218\n",
      "\n",
      "Found 133781 images in total, 42794 positive images, 90987 negative images\n",
      "Edema(C1): imbalance ratio is 0.3199\n",
      "\n",
      "Found 133781 images in total, 9055 positive images, 124726 negative images\n",
      "Consolidation(C2): imbalance ratio is 0.0677\n",
      "\n",
      "Found 133781 images in total, 41919 positive images, 91862 negative images\n",
      "Atelectasis(C3): imbalance ratio is 0.3133\n",
      "\n",
      "Found 133781 images in total, 53675 positive images, 80106 negative images\n",
      "Pleural Effusion(C4): imbalance ratio is 0.4012\n",
      "\n",
      "Multi-label mode: True, Number of classes: [5]\n",
      "------------------------------\n",
      "Found 19090 images in total, 2242 positive images, 16848 negative images\n",
      "Cardiomegaly(C0): imbalance ratio is 0.1174\n",
      "\n",
      "Found 19090 images in total, 6161 positive images, 12929 negative images\n",
      "Edema(C1): imbalance ratio is 0.3227\n",
      "\n",
      "Found 19090 images in total, 1346 positive images, 17744 negative images\n",
      "Consolidation(C2): imbalance ratio is 0.0705\n",
      "\n",
      "Found 19090 images in total, 5843 positive images, 13247 negative images\n",
      "Atelectasis(C3): imbalance ratio is 0.3061\n",
      "\n",
      "Found 19090 images in total, 7762 positive images, 11328 negative images\n",
      "Pleural Effusion(C4): imbalance ratio is 0.4066\n",
      "\n"
     ]
    }
   ],
   "source": [
    "root = os.path.join(os.getcwd(),'CheXpert_origin\\\\')\n",
    "# Index=-1 denotes multi-label with 5 diseases\n",
    "trainSet = CheXpert(csv_path=root+'train.csv',image_root_path=root,use_upsampling=False,use_frontal=True,image_size=224,mode='train',class_index=-1,verbose=True)\n",
    "testSet =  CheXpert(csv_path=root+'valid.csv',image_root_path=root,use_upsampling=False,use_frontal=True,image_size=224,mode='valid',class_index=-1,verbose=True)\n",
    "trainloader =  torch.utils.data.DataLoader(trainSet,batch_size=BATCH_SIZE,num_workers=2,shuffle=True)\n",
    "testloader =  torch.utils.data.DataLoader(testSet,batch_size=BATCH_SIZE,num_workers=2,shuffle=False)\n",
    "\n",
    "# model\n",
    "set_all_seeds(SEED) \n",
    "model = Resnet34(pretrained=True,last_activation=None,activations='elu',num_classes=5)\n",
    "model = model.cuda()\n",
    "\n",
    "# define loss & optimizer\n",
    "loss_fn = MultiLabelAUCMLoss(num_labels=5)\n",
    "optimizer = PESG(model.parameters(),\n",
    "                 loss_fn=loss_fn,\n",
    "                 lr=lr,\n",
    "                 margin=margin,\n",
    "                 epoch_decay=epoch_decay,\n",
    "                 weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a20ac6a6-6466-4d87-b49d-73049a221872",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training\n",
      "------------------------------\n",
      "(00:01:49)Epoch=0, BatchID=0, Val_AUC=0.5093, Best_Val_AUC=0.5093\n",
      "(00:04:41)Epoch=0, BatchID=400, Val_AUC=0.6835, Best_Val_AUC=0.6835\n",
      "(00:07:33)Epoch=0, BatchID=800, Val_AUC=0.7115, Best_Val_AUC=0.7115\n",
      "(00:10:23)Epoch=0, BatchID=1200, Val_AUC=0.7272, Best_Val_AUC=0.7272\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     18\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 19\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# validation  \u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m idx \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m400\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m idx \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(trainloader)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\optim\\optimizer.py:373\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    368\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    369\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    370\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    371\u001b[0m             )\n\u001b[1;32m--> 373\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    374\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    376\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\Library\\LibAUC\\libauc\\optimizers\\pesg.py:217\u001b[0m, in \u001b[0;36mPESG.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    215\u001b[0m     d_p \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mclamp(p\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mdata , \u001b[38;5;241m-\u001b[39mclip_value, clip_value) \u001b[38;5;241m+\u001b[39m weight_decay\u001b[38;5;241m*\u001b[39mp\u001b[38;5;241m.\u001b[39mdata\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m momentum \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m     param_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate[p]\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmomentum_buffer\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m param_state:\n\u001b[0;32m    219\u001b[0m         buf \u001b[38;5;241m=\u001b[39m param_state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmomentum_buffer\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mclone(d_p)\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\_tensor.py:1002\u001b[0m, in \u001b[0;36mTensor.__hash__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    992\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    993\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIterating over a tensor might cause the trace to be incorrect. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    994\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing a tensor of different shape won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt change the number of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    998\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m    999\u001b[0m         )\n\u001b[0;32m   1000\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28miter\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munbind(\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m-> 1002\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__hash__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1003\u001b[0m     \u001b[38;5;66;03m# Do NOT handle __torch_function__ here as user's default\u001b[39;00m\n\u001b[0;32m   1004\u001b[0m     \u001b[38;5;66;03m# implementation that handle most functions will most likely do it wrong.\u001b[39;00m\n\u001b[0;32m   1005\u001b[0m     \u001b[38;5;66;03m# It can be easily overridden by defining this method on the user\u001b[39;00m\n\u001b[0;32m   1006\u001b[0m     \u001b[38;5;66;03m# subclass if needed.\u001b[39;00m\n\u001b[0;32m   1007\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mid\u001b[39m(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   1009\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__dir__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# training\n",
    "print ('Start Training')\n",
    "print ('-'*30)\n",
    "begin_time = datetime.now()\n",
    "\n",
    "best_val_auc = 0 \n",
    "for epoch in range(total_epochs):\n",
    "    if epoch > 0:\n",
    "        optimizer.update_regularizer(decay_factor=10)    \n",
    "\n",
    "    for idx,data in enumerate(trainloader):\n",
    "        train_data,train_labels = data\n",
    "        train_data,train_labels = train_data.cuda(),train_labels.cuda()\n",
    "        y_pred = model(train_data)\n",
    "        y_pred = torch.sigmoid(y_pred)\n",
    "        loss = loss_fn(y_pred,train_labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "        # validation  \n",
    "        if idx % 400 == 0 or idx == len(trainloader)-1:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                test_pred = []\n",
    "                test_true = [] \n",
    "                for jdx,data in enumerate(testloader):\n",
    "                    test_data,test_labels = data\n",
    "                    test_data = test_data.cuda()\n",
    "                    y_pred = model(test_data)\n",
    "                    y_pred = torch.sigmoid(y_pred)\n",
    "                    test_pred.append(y_pred.cpu().detach().numpy())\n",
    "                    test_true.append(test_labels.numpy())\n",
    "            \n",
    "                test_true = np.concatenate(test_true)\n",
    "                test_pred = np.concatenate(test_pred)\n",
    "                val_auc_mean = np.mean(auc_roc_score(test_true,test_pred)) \n",
    "                model.train()\n",
    "                \n",
    "                if best_val_auc < val_auc_mean:\n",
    "                    best_val_auc = val_auc_mean\n",
    "                    # torch.save(model.state_dict(),os.path.join(os.getcwd(),'pth_files','origin_model.pth'))\n",
    "                    torch.save(model.state_dict(),os.path.join(os.getcwd(),'pth_files','origin_model_resnet34.pth'))\n",
    "                after_time = datetime.now()\n",
    "                time_gap = after_time-begin_time\n",
    "                time_gap = time_gap.total_seconds()\n",
    "                hours,remainders = divmod(time_gap,3600)\n",
    "                minutes,seconds = divmod(remainders,60)\n",
    "                hours = int(hours)\n",
    "                minutes = int(minutes)\n",
    "                seconds = int(seconds)\n",
    "                print(f'({hours:02d}:{minutes:02d}:{seconds:02d})Epoch={epoch},BatchID={idx},Val_AUC={val_auc_mean:.4f},Best_Val_AUC={best_val_auc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34aafbec-1f32-48f0-8dc8-ca0d794c520d",
   "metadata": {},
   "source": [
    "# Male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a08cff-0a3e-4cdc-93ad-5f47ff8e94dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = os.path.join(os.getcwd(),'CheXpert_male\\\\')\n",
    "# Index=-1 denotes multi-label with 5 diseases\n",
    "trainSet = CheXpert(csv_path=root+'train.csv',image_root_path=root,use_upsampling=False,use_frontal=True,image_size=224,mode='train',class_index=-1,verbose=True)\n",
    "testSet =  CheXpert(csv_path=root+'valid.csv',image_root_path=root,use_upsampling=False,use_frontal=True,image_size=224,mode='valid',class_index=-1,verbose=True)\n",
    "trainloader =  torch.utils.data.DataLoader(trainSet,batch_size=BATCH_SIZE,num_workers=2,shuffle=True)\n",
    "testloader =  torch.utils.data.DataLoader(testSet,batch_size=BATCH_SIZE,num_workers=2,shuffle=False)\n",
    "\n",
    "# model\n",
    "set_all_seeds(SEED)\n",
    "model = Resnet34(pretrained=True,last_activation=None,activations='elu',num_classes=5)\n",
    "model = model.cuda()\n",
    "\n",
    "# define loss & optimizer\n",
    "loss_fn = MultiLabelAUCMLoss(num_labels=5)\n",
    "optimizer = PESG(model.parameters(),\n",
    "                 loss_fn=loss_fn,\n",
    "                 lr=lr,\n",
    "                 margin=margin,\n",
    "                 epoch_decay=epoch_decay,\n",
    "                 weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8c76d6-c5a3-4d9f-9940-64ce432bbf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "print ('Start Training')\n",
    "print ('-'*30)\n",
    "begin_time = datetime.now()\n",
    "\n",
    "best_val_auc = 0 \n",
    "for epoch in range(total_epochs):\n",
    "    if epoch > 0:\n",
    "        optimizer.update_regularizer(decay_factor=10)    \n",
    "\n",
    "    for idx,data in enumerate(trainloader):\n",
    "        train_data,train_labels = data\n",
    "        train_data,train_labels  = train_data.cuda(),train_labels.cuda()\n",
    "        y_pred = model(train_data)\n",
    "        y_pred = torch.sigmoid(y_pred)\n",
    "        loss = loss_fn(y_pred,train_labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "        # validation  \n",
    "        if idx % 400 == 0 or idx == len(trainloader)-1:\n",
    "            model.eval()\n",
    "            with torch.no_grad():    \n",
    "                test_pred = []\n",
    "                test_true = [] \n",
    "                for jdx,data in enumerate(testloader):\n",
    "                    test_data,test_labels = data\n",
    "                    test_data = test_data.cuda()\n",
    "                    y_pred = model(test_data)\n",
    "                    y_pred = torch.sigmoid(y_pred)\n",
    "                    test_pred.append(y_pred.cpu().detach().numpy())\n",
    "                    test_true.append(test_labels.numpy())\n",
    "            \n",
    "                test_true = np.concatenate(test_true)\n",
    "                test_pred = np.concatenate(test_pred)\n",
    "                val_auc_mean = np.mean(auc_roc_score(test_true,test_pred)) \n",
    "                model.train()\n",
    "\n",
    "                if best_val_auc < val_auc_mean:\n",
    "                    best_val_auc = val_auc_mean\n",
    "                    # torch.save(model.state_dict(),os.path.join(os.getcwd(),'pth_files','male_model.pth'))\n",
    "                    torch.save(model.state_dict(),os.path.join(os.getcwd(),'pth_files','male_model_resnet34.pth'))\n",
    "                after_time = datetime.now()\n",
    "                time_gap = after_time-begin_time\n",
    "                time_gap = time_gap.total_seconds()\n",
    "                hours,remainders = divmod(time_gap,3600)\n",
    "                minutes,seconds = divmod(remainders,60)\n",
    "                hours = int(hours)\n",
    "                minutes = int(minutes)\n",
    "                seconds = int(seconds)\n",
    "                print(f'({hours:02d}:{minutes:02d}:{seconds:02d})Epoch={epoch},BatchID={idx},Val_AUC={val_auc_mean:.4f},Best_Val_AUC={best_val_auc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc704300-af10-4f4f-9b7a-e845c86c3f53",
   "metadata": {},
   "source": [
    "# Female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d870fe54-8431-4bc7-8da0-328fd2eaf1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = os.path.join(os.getcwd(),'CheXpert_female\\\\')\n",
    "# Index=-1 denotes multi-label with 5 diseases\n",
    "trainSet = CheXpert(csv_path=root+'train.csv',image_root_path=root,use_upsampling=False,use_frontal=True,image_size=224,mode='train',class_index=-1,verbose=True)\n",
    "testSet =  CheXpert(csv_path=root+'valid.csv',image_root_path=root,use_upsampling=False,use_frontal=True,image_size=224,mode='valid',class_index=-1,verbose=True)\n",
    "trainloader =  torch.utils.data.DataLoader(trainSet,batch_size=BATCH_SIZE,num_workers=2,shuffle=True)\n",
    "testloader =  torch.utils.data.DataLoader(testSet,batch_size=BATCH_SIZE,num_workers=2,shuffle=False)\n",
    "\n",
    "# model\n",
    "set_all_seeds(SEED)\n",
    "model = Resnet34(pretrained=True,last_activation=None,activations='elu',num_classes=5)\n",
    "model = model.cuda()\n",
    "\n",
    "# define loss & optimizer\n",
    "loss_fn = MultiLabelAUCMLoss(num_labels=5)\n",
    "optimizer = PESG(model.parameters(),\n",
    "                 loss_fn=loss_fn,\n",
    "                 lr=lr,\n",
    "                 margin=margin,\n",
    "                 epoch_decay=epoch_decay,\n",
    "                 weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd4e7ea-536e-4596-b56a-d581ee09203b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "print ('Start Training')\n",
    "print ('-'*30)\n",
    "begin_time = datetime.now()\n",
    "\n",
    "best_val_auc = 0 \n",
    "for epoch in range(total_epochs):\n",
    "    if epoch > 0:\n",
    "        optimizer.update_regularizer(decay_factor=10)    \n",
    "\n",
    "    for idx,data in enumerate(trainloader):\n",
    "        train_data,train_labels = data\n",
    "        train_data,train_labels  = train_data.cuda(),train_labels.cuda()\n",
    "        y_pred = model(train_data)\n",
    "        y_pred = torch.sigmoid(y_pred)\n",
    "        loss = loss_fn(y_pred,train_labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "        # validation  \n",
    "        if idx % 400 == 0 or idx == len(trainloader)-1:\n",
    "            model.eval()\n",
    "            with torch.no_grad():    \n",
    "                test_pred = []\n",
    "                test_true = [] \n",
    "                for jdx,data in enumerate(testloader):\n",
    "                    test_data,test_labels = data\n",
    "                    test_data = test_data.cuda()\n",
    "                    y_pred = model(test_data)\n",
    "                    y_pred = torch.sigmoid(y_pred)\n",
    "                    test_pred.append(y_pred.cpu().detach().numpy())\n",
    "                    test_true.append(test_labels.numpy())\n",
    "            \n",
    "                test_true = np.concatenate(test_true)\n",
    "                test_pred = np.concatenate(test_pred)\n",
    "                val_auc_mean = np.mean(auc_roc_score(test_true,test_pred)) \n",
    "                model.train()\n",
    "\n",
    "                if best_val_auc < val_auc_mean:\n",
    "                    best_val_auc = val_auc_mean\n",
    "                    # torch.save(model.state_dict(),os.path.join(os.getcwd(),'pth_files','female_model.pth'))\n",
    "                    torch.save(model.state_dict(),os.path.join(os.getcwd(),'pth_files','female_model_resnet34.pth'))\n",
    "                after_time = datetime.now()\n",
    "                time_gap = after_time-begin_time\n",
    "                time_gap = time_gap.total_seconds()\n",
    "                hours,remainders = divmod(time_gap,3600)\n",
    "                minutes,seconds = divmod(remainders,60)\n",
    "                hours = int(hours)\n",
    "                minutes = int(minutes)\n",
    "                seconds = int(seconds)\n",
    "                print(f'({hours:02d}:{minutes:02d}:{seconds:02d})Epoch={epoch},BatchID={idx},Val_AUC={val_auc_mean:.4f},Best_Val_AUC={best_val_auc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5015972-f499-4d82-96c9-7c7dc407b145",
   "metadata": {},
   "source": [
    "# before40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff409d2-2c9f-4f61-9e1e-3d5cc26f24c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = os.path.join(os.getcwd(),'CheXpert_before40\\\\')\n",
    "# Index=-1 denotes multi-label with 5 diseases\n",
    "trainSet = CheXpert(csv_path=root+'train.csv',image_root_path=root,use_upsampling=False,use_frontal=True,image_size=224,mode='train',class_index=-1,verbose=True)\n",
    "testSet =  CheXpert(csv_path=root+'valid.csv',image_root_path=root,use_upsampling=False,use_frontal=True,image_size=224,mode='valid',class_index=-1,verbose=True)\n",
    "trainloader =  torch.utils.data.DataLoader(trainSet,batch_size=BATCH_SIZE,num_workers=2,shuffle=True)\n",
    "testloader =  torch.utils.data.DataLoader(testSet,batch_size=BATCH_SIZE,num_workers=2,shuffle=False)\n",
    "\n",
    "# model\n",
    "set_all_seeds(SEED)\n",
    "model = Resnet34(pretrained=True,last_activation=None,activations='elu',num_classes=5)\n",
    "model = model.cuda()\n",
    "\n",
    "# define loss & optimizer\n",
    "loss_fn = MultiLabelAUCMLoss(num_labels=5)\n",
    "optimizer = PESG(model.parameters(),\n",
    "                 loss_fn=loss_fn,\n",
    "                 lr=lr,\n",
    "                 margin=margin,\n",
    "                 epoch_decay=epoch_decay,\n",
    "                 weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400b3c09-0e2f-426c-9c4c-0dabf4785d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "print ('Start Training')\n",
    "print ('-'*30)\n",
    "begin_time = datetime.now()\n",
    "\n",
    "best_val_auc = 0 \n",
    "for epoch in range(total_epochs):\n",
    "    if epoch > 0:\n",
    "        optimizer.update_regularizer(decay_factor=10)    \n",
    "\n",
    "    for idx,data in enumerate(trainloader):\n",
    "        train_data,train_labels = data\n",
    "        train_data,train_labels  = train_data.cuda(),train_labels.cuda()\n",
    "        y_pred = model(train_data)\n",
    "        y_pred = torch.sigmoid(y_pred)\n",
    "        loss = loss_fn(y_pred,train_labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "        # validation  \n",
    "        if idx % 400 == 0 or idx == len(trainloader)-1:\n",
    "            model.eval()\n",
    "            with torch.no_grad():    \n",
    "                test_pred = []\n",
    "                test_true = [] \n",
    "                for jdx,data in enumerate(testloader):\n",
    "                    test_data,test_labels = data\n",
    "                    test_data = test_data.cuda()\n",
    "                    y_pred = model(test_data)\n",
    "                    y_pred = torch.sigmoid(y_pred)\n",
    "                    test_pred.append(y_pred.cpu().detach().numpy())\n",
    "                    test_true.append(test_labels.numpy())\n",
    "            \n",
    "                test_true = np.concatenate(test_true)\n",
    "                test_pred = np.concatenate(test_pred)\n",
    "                val_auc_mean = np.mean(auc_roc_score(test_true,test_pred)) \n",
    "                model.train()\n",
    "\n",
    "                if best_val_auc < val_auc_mean:\n",
    "                    best_val_auc = val_auc_mean\n",
    "                    # torch.save(model.state_dict(),os.path.join(os.getcwd(),'pth_files','before40_model.pth'))\n",
    "                    torch.save(model.state_dict(),os.path.join(os.getcwd(),'pth_files','before40_model_resnet34.pth'))\n",
    "                after_time = datetime.now()\n",
    "                time_gap = after_time-begin_time\n",
    "                time_gap = time_gap.total_seconds()\n",
    "                hours,remainders = divmod(time_gap,3600)\n",
    "                minutes,seconds = divmod(remainders,60)\n",
    "                hours = int(hours)\n",
    "                minutes = int(minutes)\n",
    "                seconds = int(seconds)\n",
    "                print(f'({hours:02d}:{minutes:02d}:{seconds:02d})Epoch={epoch},BatchID={idx},Val_AUC={val_auc_mean:.4f},Best_Val_AUC={best_val_auc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1555ca-3c7a-4afb-9c14-6790f2375562",
   "metadata": {},
   "source": [
    "# after40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17579cf-8d37-4c33-831a-e9eb4505ff5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = os.path.join(os.getcwd(),'CheXpert_after40\\\\')\n",
    "# Index=-1 denotes multi-label with 5 diseases\n",
    "trainSet = CheXpert(csv_path=root+'train.csv',image_root_path=root,use_upsampling=False,use_frontal=True,image_size=224,mode='train',class_index=-1,verbose=True)\n",
    "testSet =  CheXpert(csv_path=root+'valid.csv',image_root_path=root,use_upsampling=False,use_frontal=True,image_size=224,mode='valid',class_index=-1,verbose=True)\n",
    "trainloader =  torch.utils.data.DataLoader(trainSet,batch_size=BATCH_SIZE,num_workers=2,shuffle=True)\n",
    "testloader =  torch.utils.data.DataLoader(testSet,batch_size=BATCH_SIZE,num_workers=2,shuffle=False)\n",
    "\n",
    "# model\n",
    "set_all_seeds(SEED)\n",
    "model = Resnet34(pretrained=True,last_activation=None,activations='elu',num_classes=5)\n",
    "model = model.cuda()\n",
    "\n",
    "# define loss & optimizer\n",
    "loss_fn = MultiLabelAUCMLoss(num_labels=5)\n",
    "optimizer = PESG(model.parameters(),\n",
    "                 loss_fn=loss_fn,\n",
    "                 lr=lr,\n",
    "                 margin=margin,\n",
    "                 epoch_decay=epoch_decay,\n",
    "                 weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c49b417-4d9e-4c03-a230-a33234c21701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "print ('Start Training')\n",
    "print ('-'*30)\n",
    "begin_time = datetime.now()\n",
    "\n",
    "best_val_auc = 0 \n",
    "for epoch in range(total_epochs):\n",
    "    if epoch > 0:\n",
    "        optimizer.update_regularizer(decay_factor=10)    \n",
    "\n",
    "    for idx,data in enumerate(trainloader):\n",
    "        train_data,train_labels = data\n",
    "        train_data,train_labels  = train_data.cuda(),train_labels.cuda()\n",
    "        y_pred = model(train_data)\n",
    "        y_pred = torch.sigmoid(y_pred)\n",
    "        loss = loss_fn(y_pred,train_labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "        # validation  \n",
    "        if idx % 400 == 0 or idx == len(trainloader)-1:\n",
    "            model.eval()\n",
    "            with torch.no_grad():    \n",
    "                test_pred = []\n",
    "                test_true = [] \n",
    "                for jdx,data in enumerate(testloader):\n",
    "                    test_data,test_labels = data\n",
    "                    test_data = test_data.cuda()\n",
    "                    y_pred = model(test_data)\n",
    "                    y_pred = torch.sigmoid(y_pred)\n",
    "                    test_pred.append(y_pred.cpu().detach().numpy())\n",
    "                    test_true.append(test_labels.numpy())\n",
    "            \n",
    "                test_true = np.concatenate(test_true)\n",
    "                test_pred = np.concatenate(test_pred)\n",
    "                val_auc_mean = np.mean(auc_roc_score(test_true,test_pred)) \n",
    "                model.train()\n",
    "\n",
    "                if best_val_auc < val_auc_mean:\n",
    "                    best_val_auc = val_auc_mean\n",
    "                    # torch.save(model.state_dict(),os.path.join(os.getcwd(),'pth_files','after40_model.pth'))\n",
    "                    torch.save(model.state_dict(),os.path.join(os.getcwd(),'pth_files','after40_model_resnet34.pth'))\n",
    "                after_time = datetime.now()\n",
    "                time_gap = after_time-begin_time\n",
    "                time_gap = time_gap.total_seconds()\n",
    "                hours,remainders = divmod(time_gap,3600)\n",
    "                minutes,seconds = divmod(remainders,60)\n",
    "                hours = int(hours)\n",
    "                minutes = int(minutes)\n",
    "                seconds = int(seconds)\n",
    "                print(f'({hours:02d}:{minutes:02d}:{seconds:02d})Epoch={epoch},BatchID={idx},Val_AUC={val_auc_mean:.4f},Best_Val_AUC={best_val_auc:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
